



WG Working Group                                             E. Rescorla
Internet-Draft                                                   Mozilla
Intended status: Informational                           1 December 2022
Expires: 4 June 2023


                       Privacy for Safe Browsing
              draft-rescorla-safe-browsing-privacy-latest

Abstract

   The Google Safe Browsing service is used by browsers to identify
   potentially malicious web sites, for example, sites that distribute
   malware or that are part of a phishing campaign.  Browsers may warn
   users before allowing navigation to a site that is flagged by the
   Safe Browsing service, or take other steps to reduce the chance that
   a user is harmed by a malicious site.  The current design of the Safe
   Browsing protocol allows the service operator to learn some
   information about which sites the user is visiting.  This document
   describes a design which has improved privacy properties.

About This Document

   This note is to be removed before publishing as an RFC.

   The latest revision of this draft can be found at
   https://example.com/LATEST.  Status information for this document may
   be found at https://datatracker.ietf.org/doc/draft-rescorla-safe-
   browsing-privacy/.

   Discussion of this document takes place on the WG Working Group
   mailing list (mailto:WG@example.com), which is archived at
   https://example.com/WG.

   Source for this draft and an issue tracker can be found at
   https://github.com/USER/REPO.

Status of This Memo

   This Internet-Draft is submitted in full conformance with the
   provisions of BCP 78 and BCP 79.

   Internet-Drafts are working documents of the Internet Engineering
   Task Force (IETF).  Note that other groups may also distribute
   working documents as Internet-Drafts.  The list of current Internet-
   Drafts is at https://datatracker.ietf.org/drafts/current/.

   Internet-Drafts are draft documents valid for a maximum of six months
   and may be updated, replaced, or obsoleted by other documents at any
   time.  It is inappropriate to use Internet-Drafts as reference
   material or to cite them other than as "work in progress."

   This Internet-Draft will expire on 4 June 2023.

Copyright Notice

   Copyright (c) 2022 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to BCP 78 and the IETF Trust's Legal
   Provisions Relating to IETF Documents (https://trustee.ietf.org/
   license-info) in effect on the date of publication of this document.
   Please review these documents carefully, as they describe your rights
   and restrictions with respect to this document.  Code Components
   extracted from this document must include Revised BSD License text as
   described in Section 4.e of the Trust Legal Provisions and are
   provided without warranty as described in the Revised BSD License.

Table of Contents

   1.  Introduction
     1.1.  Privacy Issues
     1.2.  Timeliness Issues
   2.  Measuring Safe Browsing Privacy
   3.  An Improved Design
     3.1.  Timeliness
     3.2.  Bandwidth Comparison
   4.  Alternative Designs
     4.1.  Proxies
     4.2.  PIR
       4.2.1.  Partial PIR
       4.2.2.  Hybrid PIR
   5.  Conventions and Definitions
   6.  Security Considerations
   7.  IANA Considerations
   8.  References
     8.1.  Normative References
     8.2.  Informative References
   Appendix A.  Hash Length Selection
   Acknowledgments
   Author's Address

1.  Introduction

   At a high level, Safe Browsing works by having a list of blocked
   strings (domain names and URL prefixes) on the Safe Browsing server.
   Prior to visiting a site, the browser checks that the URL and its
   components are not on the list; if the URL is on the list, the
   browser generates an error and aborts navigation.  Although the
   current API [SB] exposes an endpoint that allows for checking a
   single string, browsers do not use this API because doing so would
   leak a user's browsing history, as the service could build a
   longitudinal list of queries for each IP address.

   Instead, the current protocol uses a protocol that provides partial
   Private Information Retrieval (PIR).  At a high level, this protocol
   works as follows:

   *  The server computes a hash of each blocked string and provides the
      client with a list of unique hash _prefixes_. Typically these
      prefixes are 32 bits long.  The clients periodically update the
      prefix list.

   *  The client computes the hashes of each string to be queried in the
      Safe Browsing list, and determines whether the prefix of any of
      those hashes appears on the list provided by the Safe Browsing
      server.  Any hash prefixes that do not appear on the server's list
      are OK to connect to.

   *  The client sends the set of prefixes that did appear on the list
      to the server, which responds with the set of full hashes matching
      each prefix.

   *  The client then determines whether the full (256-bit) hashes of
      its query strings appear in the set of full hashes received from
      the server.  Any that match are treated as flagged by the Safe
      Browsing service.

   This design reduces the number of times that clients must contact the
   server in order to determine the Safe Browsing status of a site,
   while also avoiding the cost of keeping a full copy of the list of
   blocked strings at each client.

1.1.  Privacy Issues

   There are on the order of a million (2^20) strings in the database
   and there are 2^32 possible hash prefixes, so approximately 2^-12
   (1/4096) hash prefixes corresponds to a blocked entry.  This means
   that about 1/4096 strings will require a database lookup.  Naively,
   this would mean that the server would obtain information about 1/4096
   of the URLs that a user visits, but the number is probably closer to
   1/1000 because the client queries for prefixes of the URL as well as
   the whole URL; the precise number varies depending on the number of
   components in each URL.  Moreover, the server can opt to receive
   information about given sites by spuriously publishing their hash
   prefixes.  A full privacy analysis of Safe Browsing is out of scope
   for this document, but it should be clear that these properties are
   not ideal.

1.2.  Timeliness Issues

   In addition to the privacy issues discussed in the previous section,
   the current Safe Browsing design has suboptimal timeliness
   properties.  Specifically, because the client periodically updates
   the hash prefix list, and does not check with the server for non-
   matching hashes, it is possible to have false negative results if the
   hash was added during the update interval.  Because phishing attacks
   are often of quite short duration, this has a significant impact on
   the effectiveness of Safe Browsing.

   Because the client retrieves the full-length hashes for each matched
   prefix, these results are inherently more timely.  However, in
   principle if the client caches the full-length hashes, this can still
   manifest incorrect results, for instance, a false negative if prefix
   X is retrieved and then X || Y is added, or, a false positive if X is
   retrieved, yields X || Y, and then X || Y is removed.

2.  Measuring Safe Browsing Privacy

   Ideally, safe browsing queries could be served in a way that provides
   information-theoretic security, meaning no information at all about
   browsing history is revealed to the server, or in a way that provides
   computational security, meaning a computationally-bounded server
   cannot learn anything about the browsing history.  However, it may be
   significantly easier to implement a scheme in which the server learns
   a bounded, small amount of information about the browsing history.
   Deciding whether a given query reveals a "small" amount of
   information is difficult.  Learning specific sites that a user has or
   is very likely to have visited, is probably more than a "small"
   amount of information.  Being able to infer probabilities of the user
   having visited sites that are close, but not identical, to the
   probabilities of an average user having visited those sites, might be
   considered a "small" amount of infomation.  Differential privacy
   [cite] provides one framework for assessing how much information is
   revealed.  [Toledo et al.] analyze several PIR schemes in the
   framework of differential privacy.  However, while differential
   privacy provides a framework for analysis, it does not establish the
   amount of information leakage that is acceptable in any particular
   application.

   [TODO: Discuss epsilon and delta, and the impact of zero-probability
   events on achievable values thereof?]

   If the probability that a random internet user has visited a
   particular site is $10^{-6}$, and the probability that a user who has
   made a certain query to the safe browsing server has visited that
   site is $10^{-4}$, is that a meaningful loss of privacy?  What if the
   probability that a random internet user has visited a particular site
   is $10^{-2}$, and that increases to 0.99 for users who have made a
   particular safe browsing query?

   The existing "dummy requests" scheme implemented in Firefox for safe
   browsing queries is subject to this kind of distortion.  Safe
   browsing records associated with very popular sites will be requested
   much more frequently due to actual navigation to the popular site,
   than they will due to random selection for a dummy request.  An open
   question is the extent to which any amount of "plausible deniability"
   is sufficient.  That is, if there is any chance, no matter how small,
   that a particular safe browsing lookup does not indicate actual
   browsing activity, does that provide sufficient privacy for safe
   browsing requests?

   [De Blasio] describes a scheme for SCT auditing in Chrome that
   provides a level of privacy by requesting blocks of SCT hashes.  It
   is said to be providing k-anonymity, but in the strictest sense of
   the term that may not be true -- there are a total of k records that
   could be the record of interest, but there are not necessarily k
   users making the same set of requests.

3.  An Improved Design

   The privacy issues described in Section 1.1 result from the client
   needing to contact the server to verify the hash, which is a
   consequence of the 32-bit hash prefix being too short to provide
   precise results.  Because the client only contacts the server for
   matching prefixes, this leaks browsing history.

   This is easily addressed by having the server provide longer hashes,
   on the order of 128 bits (see Appendix A).  This provides an
   immediate improvement in privacy because the client can immediately
   decide the status of any URL, thus avoiding any URL-dependent queries
   to the server.  In addition, it provides a performance benefit
   because the client does not need to round-trip to the server.

3.1.  Timeliness

   A strict "full hash" design has inferior timeliness properties.

   Specifically, because the client need not confirm matches with the
   server, any hashes which are incorrectly added to the list--or need
   to be removed for some other reason--remain until the next time the
   client updates; this creates false positives.  By contrast, with the
   current design the client makes its final blocklist checks in real
   time.

   This design is also slightly worse for false negatives.  Consider the
   following timeline:

   T0      Database contains X || Y
   T1      Client downloads database
   T2      X || Z added to database
   T3      Client attempts to go to X || Z

   With the current design, the client will check with the server at
   time T3 and thus will refuse to visit the site.  By contrast, with a
   full hash version, the client will check the database at T3, find
   only X || Y, and continue.

   Both of these issues can be addressed by having the client receive
   more frequent updates from the server.  It may also be useful for the
   server to have a mechanism to publish high prioirity updates, for
   instance by having the client poll for them in real-time or by having
   a publish/subscribe type notification channel.

   It is important to note that because none of the client actions in
   this scenario depend on the browsing history, it is safe to do them
   all on a single communication channel, even though this allows them
   to be linked.  This is a potential issue with alternative designs
   based on proxies, as described in Section 4.1.

3.2.  Bandwidth Comparison

   [KC20] provides some figures for the storage and data transfer costs
   of various safe browsing schemes.  For the existing safe browsing
   implementation, the client's database size is 4.3 MB and the ongoing
   data transfer to each client is 3.0 MB/month.  To maintain a database
   at the client containing complete hashes would increase the client's
   database size to 91.8 MB, and the monthly data transfer to 13.2 MB.
   The "Checklist" PIR scheme described in [KC20] requires a client
   database of 24.5 MB, and monthly data transfer of 9.8 MB.  (Unlike
   the non-PIR schemes, the initial server-to-client data transfer in
   this case is roughly 50% of the final client database size.  For the
   non-PIR schemes, the initial transfer size is comparable to the
   database size.)

4.  Alternative Designs

   There are two main alternative designs for preventing the server from
   learning the client's queries.

4.1.  Proxies

   The obvious approach is to simply use a proxy (e.g., OHAI
   [I-D.ietf-ohai-ohttp] between the client and the server, thus
   concealing the client's IP address.  This provides good privacy as
   long as the server and proxy do not collude.

   However, the queries need to be unlinkable in order to prevent
   situations in which the server determines the client's identity from
   part of its browsing history and then is able to link that to some
   incriminating part of the user's activity.  This is a particular
   problem in the context of proposals like Safe Browsing v5 in which
   the client performs real-time checks for most URLs (filtered by an
   allow list), and thus the server sees more of the user's history.

   This requirement for unlinkability makes the use of connection-
   oriented proxies such as MASQUE [I-D.ietf-masque-connect-udp]
   problematic, as a new connection must be initiated for each request,
   which introduces latency.  In addition, it creates problems for anti-
   DoS mechanisms which depend on giving clients a short-term persistent
   identifier; this allows for the detection of abusive behavior, but
   also permits linkability during the lifetime of the identifier.

4.2.  PIR

   An alternative approach is to perform each request over a Private
   Information Retrieval (PIR) protocol.  Unfortunately, effective PIR
   protocols have much higher bandwidth and computational costs than the
   existing design.  [TODO: Wood]

   Table 2 in [CG19] provides an overview of known PIR protocols for
   both the single-server and two-server cases.  The best known
   protocols have $O(\sqrt{n})$ online server computation, but require
   amortizing offline (preparatory) computation over many queries to
   achieve that.  Depending on the rate of change of the safe browsing
   database, these schemes may not be applicable.  [MZRA22] adapts the
   [CG19] scheme for dynamic databases, but in a way that does not apply
   to PIR-by-keywords.  For the fully online case, [GI14] has $O(n)$
   online computation and $O(\log n)$ communication.

   The techniques of [BIM04] can trade reduced online server computation
   for increased server storage.  Given the modest size of the safe
   browsing database, these schemes may be useful.

4.2.1.  Partial PIR

   An approach that provides "partially private information retrieval"
   like the following may be viable for queries to a safe browsing
   database with $O(10^6)$ records:

   *  The safe browsing database is divided into $O(250)$ buckets.  Most
      sites are assigned to one of these buckets using a hash.  Each
      lookup leaks which bucket it is searching.  As long as
      sufficiently many and varied sites are assigned to each bucket,
      this leakage may be deemed acceptable.  Popular sites are
      replicated in every bucket, and may be looked up in any bucket at
      the client's discretion, thus leaking nothing.

   *  Within each bucket, a PIR scheme is used to search the $O(4 \times
      10^3)$ records assigned to that bucket.

4.2.2.  Hybrid PIR

   The current size of the safe browsing database is approximately three
   million 32-bit prefixes.  Each day, around ten thousand prefixes are
   added to the database, and around ten thousand prefixes are removed
   from the database.  Only around 7% of prefixes added to the database
   are removed within 7 days.  Around 40% of removals each day happen
   between 5 and 7 AM PDT which could reflect a batch process, or could
   be a start-of-day effect.

   This suggests a hybrid approach for querying the safe browsing
   database.  For each lookup, queries are made over two databases:

   *  One database contains the full safe browsing database, and is
      updated daily.  This database would contain $O(10^6)$ records, and
      would be queried with the offline/online PIR scheme of [CG19].

   *  The second database contains a representation of the changes to
      the safe browsing database since the most recent daily snapshot.
      This database would contain $O(10^4)$ records, and would be
      queried with a DPF-based PIR.  Because 40% of removals occur in a
      restricted time window, and removals in general may not be time
      sensitive, it may be possible to exclude some removals from this
      database.

   Rather than distribute fresh hints for the large database each day,
   it may be easier to distribute the full detail of changes to the
   database and let the client update its hints accordingly.  Because
   the client does not maintain a full copy of the database, full hashes
   of both additions and removals would need to be distributed, for an
   estimated cost of 26 MB/month (i.e. approximately double the cost of
   incremental updates of a full database).  Compared with Checklist,
   which maintains a series of exponentially growing buckets, the client
   database size and initial transfer might be reduced by approximately
   50% in this scheme.

5.  Conventions and Definitions

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
   "OPTIONAL" in this document are to be interpreted as described in
   BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all
   capitals, as shown here.

6.  Security Considerations

   TODO Security

7.  IANA Considerations

   This document has no IANA actions.

8.  References

8.1.  Normative References

   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
              Requirement Levels", BCP 14, RFC 2119,
              DOI 10.17487/RFC2119, March 1997,
              <https://www.rfc-editor.org/rfc/rfc2119>.

   [RFC8174]  Leiba, B., "Ambiguity of Uppercase vs Lowercase in RFC
              2119 Key Words", BCP 14, RFC 8174, DOI 10.17487/RFC8174,
              May 2017, <https://www.rfc-editor.org/rfc/rfc8174>.

8.2.  Informative References

   [I-D.ietf-masque-connect-udp]
              Schinazi, D., "Proxying UDP in HTTP", Work in Progress,
              Internet-Draft, draft-ietf-masque-connect-udp-15, 17 June
              2022, <https://datatracker.ietf.org/doc/html/draft-ietf-
              masque-connect-udp-15>.

   [I-D.ietf-ohai-ohttp]
              Thomson, M. and C. A. Wood, "Oblivious HTTP", Work in
              Progress, Internet-Draft, draft-ietf-ohai-ohttp-05, 26
              September 2022, <https://datatracker.ietf.org/doc/html/
              draft-ietf-ohai-ohttp-05>.

   [SB]       Google, "Safe Browsing APIs (v4)", n.d.,
              <https://developers.google.com/safe-browsing/v4>.

Appendix A.  Hash Length Selection

   The false positive rate of a system with a b-bit hash is effectively
   2^{-(b-20)}. This suggests that an 80 bit hash (false positive rate
   2^-60) is sufficient assuming only random collisions.  However, an
   attacker might be able to search the ~2^60 bit space to find a
   colliding hash and then arrange for that URL to host malware or
   phishing content, thus making a given site unvisitable.  This
   suggests that we want something more like 128 bits, which requires
   >2^100 effort to find a value which hashes to a database entry.

Acknowledgments

Author's Address

   Eric Rescorla
   Mozilla
   Email: ekr@example.com
