



WG Working Group                                             E. Rescorla
Internet-Draft                                                   Mozilla
Intended status: Informational                           24 October 2022
Expires: 27 April 2023


                       Privacy for Safe Browsing
              draft-rescorla-safe-browsing-privacy-latest

Abstract

   The Google Safe Browsing service is used by browsers to identify
   potentially malicious web sites, for example, sites that distribute
   malware or that are part of a phishing campaign.  Browsers may warn
   users before allowing navigation to a site that is flagged by the
   Safe Browsing service, or take other steps to reduce the chance that
   a user is harmed by a malicious site.  The current design of the Safe
   Browsing protocol allows the service operator to learn some
   information about which sites the user is visiting.  This document
   describes a design which has improved privacy properties.

About This Document

   This note is to be removed before publishing as an RFC.

   The latest revision of this draft can be found at
   https://example.com/LATEST.  Status information for this document may
   be found at https://datatracker.ietf.org/doc/draft-rescorla-safe-
   browsing-privacy/.

   Discussion of this document takes place on the WG Working Group
   mailing list (mailto:WG@example.com), which is archived at
   https://example.com/WG.

   Source for this draft and an issue tracker can be found at
   https://github.com/USER/REPO.

Status of This Memo

   This Internet-Draft is submitted in full conformance with the
   provisions of BCP 78 and BCP 79.

   Internet-Drafts are working documents of the Internet Engineering
   Task Force (IETF).  Note that other groups may also distribute
   working documents as Internet-Drafts.  The list of current Internet-
   Drafts is at https://datatracker.ietf.org/drafts/current/.

   Internet-Drafts are draft documents valid for a maximum of six months
   and may be updated, replaced, or obsoleted by other documents at any
   time.  It is inappropriate to use Internet-Drafts as reference
   material or to cite them other than as "work in progress."

   This Internet-Draft will expire on 27 April 2023.

Copyright Notice

   Copyright (c) 2022 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to BCP 78 and the IETF Trust's Legal
   Provisions Relating to IETF Documents (https://trustee.ietf.org/
   license-info) in effect on the date of publication of this document.
   Please review these documents carefully, as they describe your rights
   and restrictions with respect to this document.  Code Components
   extracted from this document must include Revised BSD License text as
   described in Section 4.e of the Trust Legal Provisions and are
   provided without warranty as described in the Revised BSD License.

Table of Contents

   1.  Introduction
     1.1.  Privacy Issues
     1.2.  Timeliness Issues
   2.  An Improved Design
     2.1.  Timeliness
     2.2.  Bandwidth Comparison
   3.  Alternative Designs
     3.1.  Proxies
     3.2.  PIR
   4.  Conventions and Definitions
   5.  Security Considerations
   6.  IANA Considerations
   7.  References
     7.1.  Normative References
     7.2.  Informative References
   Appendix A.  Hash Length Selection
   Acknowledgments
   Author's Address

1.  Introduction

   At a high level, Safe Browsing works by having a list of blocked
   strings (domain names and URL prefixes) on the Safe Browsing server.
   Prior to visiting a site, the browser checks that the URL and its
   components are not on the list; if the URL is on the list, the
   browser generates an error and aborts navigation.  Although the
   current API [SB] exposes an endpoint that allows for checking a
   single string, browsers do not use this API because doing so would
   leak a user's browsing history, as the service could build a
   longitudinal list of queries for each IP address.

   Instead, the current protocol uses a protocol that provides partial
   Private Information Retrieval (PIR).  At a high level, this protocol
   works as follows:

   *  The server computes a hash of each blocked string and provides the
      client with a list of unique hash _prefixes_. Typically these
      prefixes are 32 bits long.  The clients periodically update the
      prefix list.

   *  The client computes the hashes of each string to be queried in the
      Safe Browsing list, and determines whether the prefix of any of
      those hashes appears on the list provided by the Safe Browsing
      server.  Any hash prefixes that do not appear on the server's list
      are OK to connect to.

   *  The client sends the set of prefixes that did appear on the list
      to the server, which responds with the set of full hashes matching
      each prefix.

   *  The client then determines whether the full (256-bit) hashes of
      its query strings appear in the set of full hashes received from
      the server.  Any that match are treated as flagged by the Safe
      Browsing service.

   This design reduces the number of times that clients must contact the
   server in order to determine the Safe Browsing status of a site,
   while also avoiding the cost of keeping a full copy of the list of
   blocked strings at each client.

1.1.  Privacy Issues

   There are on the order of a million (2^20) strings in the database
   and there are 2^32 possible hash prefixes, so approximately 2^-12
   (1/4096) hash prefixes corresponds to a blocked entry.  This means
   that about 1/4096 strings will require a database lookup.  Naively,
   this would mean that the server would obtain information about 1/4096
   of the URLs that a user visits, but the number is probably closer to
   1/1000 because the client queries for prefixes of the URL as well as
   the whole URL; the precise number varies depending on the number of
   components in each URL.  Moreover, the server can opt to receive
   information about given sites by spuriously publishing their hash
   prefixes.  A full privacy analysis of Safe Browsing is out of scope
   for this document, but it should be clear that these properties are
   not ideal.

1.2.  Timeliness Issues

   In addition to the privacy issues discussed in the previous section,
   the current Safe Browsing design has suboptimal timeliness
   properties.  Specifically, because the client periodically updates
   the hash prefix list, and does not check with the server for non-
   matching hashes, it is possible to have false negative results if the
   hash was added during the update interval.  Because phishing attacks
   are often of quite short duration, this has a significant impact on
   the effectiveness of Safe Browsing.

   Because the client retrieves the full-length hashes for each matched
   prefix, these results are inherently more timely.  However, in
   principle if the client caches the full-length hashes, this can still
   manifest incorrect results, for instance, a false negative if prefix
   X is retrieved and then X || Y is added, or, a false positive if X is
   retrieved, yields X || Y, and then X || Y is removed.

2.  An Improved Design

   The privacy issues described in Section 1.1 result from the client
   needing to contact the server to verify the hash, which is a
   consequence of the 32-bit hash prefix being too short to provide
   precise results.  Because the client only contacts the server for
   matching prefixes, this leaks browsing history.

   This is easily addressed by having the server provide longer hashes,
   on the order of 128 bits (see Appendix A).  This provides an
   immediate improvement in privacy because the client can immediately
   decide the status of any URL, thus avoiding any URL-dependent queries
   to the server.  In addition, it provides a performance benefit
   because the client does not need to round-trip to the server.

2.1.  Timeliness

   A strict "full hash" design has inferior timeliness properties.

   Specifically, because the client need not confirm matches with the
   server, any hashes which are incorrectly added to the list--or need
   to be removed for some other reason--remain until the next time the
   client updates; this creates false positives.  By contrast, with the
   current design the client makes its final blocklist checks in real
   time.

   This design is also slightly worse for false negatives.  Consider the
   following timeline:

   T0      Database contains X || Y
   T1      Client downloads database
   T2      X || Z added to database
   T3      Client attempts to go to X || Z

   With the current design, the client will check with the server at
   time T3 and thus will refuse to visit the site.  By contrast, with a
   full hash version, the client will check the database at T3, find
   only X || Y, and continue.

   Both of these issues can be addressed by having the client receive
   more frequent updates from the server.  It may also be useful for the
   server to have a mechanism to publish high prioirity updates, for
   instance by having the client poll for them in real-time or by having
   a publish/subscribe type notification channel.

   It is important to note that because none of the client actions in
   this scenario depend on the browsing history, it is safe to do them
   all on a single communication channel, even though this allows them
   to be linked.  This is a potential issue with alternative designs
   based on proxies, as described in Section 3.1.

2.2.  Bandwidth Comparison

   [TODO: how does this compare to SB now?]

3.  Alternative Designs

   There are two main alternative designs for preventing the server from
   learning the client's queries.

3.1.  Proxies

   The obvious approach is to simply use a proxy (e.g., OHAI
   [I-D.ietf-ohai-ohttp] between the client and the server, thus
   concealing the client's IP address.  This provides good privacy as
   long as the server and proxy do not collude.

   However, the queries need to be unlinkable in order to prevent
   situations in which the server determines the client's identity from
   part of its browsing history and then is able to link that to some
   incriminating part of the user's activity.  This is a particular
   problem in the context of proposals like Safe Browsing v5 in which
   the client performs real-time checks for most URLs (filtered by an
   allow list), and thus the server sees more of the user's history.

   This requirement for unlinkability makes the use of connection-
   oriented proxies such as MASQUE [I-D.ietf-masque-connect-udp]
   problematic, as a new connection must be initiated for each request,
   which introduces latency.  In addition, it creates problems for anti-
   DoS mechanisms which depend on giving clients a short-term persistent
   identifier; this allows for the detection of abusive behavior, but
   also permits linkability during the lifetime of the identifier.

3.2.  PIR

   An alternative approach is to perform each request over a Private
   Information Retrieval (PIR) protocol.  Unfortunately, effective PIR
   protocols have much higher bandwidth and computational costs than the
   existing design.  [TODO: Wood]

4.  Conventions and Definitions

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
   "OPTIONAL" in this document are to be interpreted as described in
   BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all
   capitals, as shown here.

5.  Security Considerations

   TODO Security

6.  IANA Considerations

   This document has no IANA actions.

7.  References

7.1.  Normative References

   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
              Requirement Levels", BCP 14, RFC 2119,
              DOI 10.17487/RFC2119, March 1997,
              <https://www.rfc-editor.org/rfc/rfc2119>.

   [RFC8174]  Leiba, B., "Ambiguity of Uppercase vs Lowercase in RFC
              2119 Key Words", BCP 14, RFC 8174, DOI 10.17487/RFC8174,
              May 2017, <https://www.rfc-editor.org/rfc/rfc8174>.

7.2.  Informative References

   [I-D.ietf-masque-connect-udp]
              Schinazi, D., "Proxying UDP in HTTP", Work in Progress,
              Internet-Draft, draft-ietf-masque-connect-udp-15, 17 June
              2022, <https://datatracker.ietf.org/doc/html/draft-ietf-
              masque-connect-udp-15>.

   [I-D.ietf-ohai-ohttp]
              Thomson, M. and C. A. Wood, "Oblivious HTTP", Work in
              Progress, Internet-Draft, draft-ietf-ohai-ohttp-05, 26
              September 2022, <https://datatracker.ietf.org/doc/html/
              draft-ietf-ohai-ohttp-05>.

   [SB]       Google, "Safe Browsing APIs (v4)", n.d.,
              <https://developers.google.com/safe-browsing/v4>.

Appendix A.  Hash Length Selection

   The false positive rate of a system with a b-bit hash is effectively
   2^{-(b-20)}. This suggests that an 80 bit hash (false positive rate
   2^-60) is sufficient assuming only random collisions.  However, an
   attacker might be able to search the ~2^60 bit space to find a
   colliding hash and then arrange for that URL to host malware or
   phishing content, thus making a given site unvisitable.  This
   suggests that we want something more like 128 bits, which requires
   >2^100 effort to find a value which hashes to a database entry.

Acknowledgments

Author's Address

   Eric Rescorla
   Mozilla
   Email: ekr@example.com
